{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Credit Card Fraud Detection revised\n",
    "\n",
    "we return to the credit card use case (last time we used Random Forests).\n",
    "\n",
    "\n",
    "## Pre-Stage\n",
    "Use your pre-processing from the last assignment as input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#download data\n",
    "!unzip creditcard.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your preprocessing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-1.360</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>2.536</td>\n",
       "      <td>1.378</td>\n",
       "      <td>-0.338</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.364</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.278</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.134</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>149.620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.192</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.060</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>0.085</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>-0.639</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.015</td>\n",
       "      <td>2.690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.358</td>\n",
       "      <td>-1.340</td>\n",
       "      <td>1.773</td>\n",
       "      <td>0.380</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>1.800</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.248</td>\n",
       "      <td>-1.515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.909</td>\n",
       "      <td>-0.689</td>\n",
       "      <td>-0.328</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>378.660</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>1.793</td>\n",
       "      <td>-0.863</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>1.247</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-1.387</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-1.176</td>\n",
       "      <td>0.647</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.061</td>\n",
       "      <td>123.500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.000</td>\n",
       "      <td>-1.158</td>\n",
       "      <td>0.878</td>\n",
       "      <td>1.549</td>\n",
       "      <td>0.403</td>\n",
       "      <td>-0.407</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.593</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>0.818</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.798</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.215</td>\n",
       "      <td>69.990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time     V1     V2    V3     V4     V5     V6     V7     V8     V9  ...  \\\n",
       "0 0.000 -1.360 -0.073 2.536  1.378 -0.338  0.462  0.240  0.099  0.364  ...   \n",
       "1 0.000  1.192  0.266 0.166  0.448  0.060 -0.082 -0.079  0.085 -0.255  ...   \n",
       "2 1.000 -1.358 -1.340 1.773  0.380 -0.503  1.800  0.791  0.248 -1.515  ...   \n",
       "3 1.000 -0.966 -0.185 1.793 -0.863 -0.010  1.247  0.238  0.377 -1.387  ...   \n",
       "4 2.000 -1.158  0.878 1.549  0.403 -0.407  0.096  0.593 -0.271  0.818  ...   \n",
       "\n",
       "     V21    V22    V23    V24    V25    V26    V27    V28  Amount  Class  \n",
       "0 -0.018  0.278 -0.110  0.067  0.129 -0.189  0.134 -0.021 149.620      0  \n",
       "1 -0.226 -0.639  0.101 -0.340  0.167  0.126 -0.009  0.015   2.690      0  \n",
       "2  0.248  0.772  0.909 -0.689 -0.328 -0.139 -0.055 -0.060 378.660      0  \n",
       "3 -0.108  0.005 -0.190 -1.176  0.647 -0.222  0.063  0.061 123.500      0  \n",
       "4 -0.009  0.798 -0.137  0.141 -0.206  0.502  0.219  0.215  69.990      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('creditcard.csv')\n",
    "pd.set_option('display.float', '{:.3f}'.format)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_samp, y_samp = SMOTE(random_state=1).fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_samp= scaler.fit_transform(X_samp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Train a MLP-Network\n",
    "* Train and evaluate the model \n",
    "* Compare the results to the Random Forrest \n",
    "* Tune the hyper-parameters (like number of layers, neurons per layer, learning-rate and number of epochs ) to optimize the results\n",
    "\n",
    "See: https://keras.io/api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                1984      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 14,529\n",
      "Trainable params: 14,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(units=64, kernel_initializer='normal', input_dim=30, activation='relu'),\n",
    "    Dense(units=64, kernel_initializer='normal', activation='relu'),\n",
    "    #Dropout(0.25),\n",
    "    Dense(64, kernel_initializer='normal', activation='relu'),\n",
    "    Dense(64, kernel_initializer='normal', activation='relu'),\n",
    "    Dense(1, kernel_initializer='normal', activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',f1_m, precision_m, recall_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6397/6397 [==============================] - 9s 1ms/step - loss: 0.0251 - accuracy: 0.9919 - f1_m: 0.9902 - precision_m: 0.9932 - recall_m: 0.9884 - val_loss: 0.0055 - val_accuracy: 0.9984 - val_f1_m: 0.9992 - val_precision_m: 1.0000 - val_recall_m: 0.9984\n",
      "Epoch 2/10\n",
      "6397/6397 [==============================] - 8s 1ms/step - loss: 0.0071 - accuracy: 0.9979 - f1_m: 0.9976 - precision_m: 0.9970 - recall_m: 0.9982 - val_loss: 0.0040 - val_accuracy: 0.9989 - val_f1_m: 0.9994 - val_precision_m: 1.0000 - val_recall_m: 0.9989\n",
      "Epoch 3/10\n",
      "6397/6397 [==============================] - 9s 1ms/step - loss: 0.0052 - accuracy: 0.9986 - f1_m: 0.9984 - precision_m: 0.9979 - recall_m: 0.9990 - val_loss: 0.0011 - val_accuracy: 0.9996 - val_f1_m: 0.9998 - val_precision_m: 1.0000 - val_recall_m: 0.9996\n",
      "Epoch 4/10\n",
      "6397/6397 [==============================] - 8s 1ms/step - loss: 0.0040 - accuracy: 0.9989 - f1_m: 0.9987 - precision_m: 0.9984 - recall_m: 0.9991 - val_loss: 0.0030 - val_accuracy: 0.9987 - val_f1_m: 0.9993 - val_precision_m: 1.0000 - val_recall_m: 0.9987\n",
      "Epoch 5/10\n",
      "6397/6397 [==============================] - 8s 1ms/step - loss: 0.0031 - accuracy: 0.9991 - f1_m: 0.9990 - precision_m: 0.9988 - recall_m: 0.9993 - val_loss: 1.0733e-04 - val_accuracy: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
      "Epoch 6/10\n",
      "6397/6397 [==============================] - 8s 1ms/step - loss: 0.0029 - accuracy: 0.9992 - f1_m: 0.9991 - precision_m: 0.9989 - recall_m: 0.9994 - val_loss: 0.0072 - val_accuracy: 0.9983 - val_f1_m: 0.9991 - val_precision_m: 1.0000 - val_recall_m: 0.9983\n",
      "Epoch 7/10\n",
      "6397/6397 [==============================] - 8s 1ms/step - loss: 0.0023 - accuracy: 0.9993 - f1_m: 0.9992 - precision_m: 0.9990 - recall_m: 0.9994 - val_loss: 0.0013 - val_accuracy: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n",
      "Epoch 8/10\n",
      "6397/6397 [==============================] - 9s 1ms/step - loss: 0.0021 - accuracy: 0.9994 - f1_m: 0.9993 - precision_m: 0.9992 - recall_m: 0.9995 - val_loss: 7.3122e-04 - val_accuracy: 0.9999 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 0.9999\n",
      "Epoch 9/10\n",
      "6397/6397 [==============================] - 8s 1ms/step - loss: 0.0018 - accuracy: 0.9995 - f1_m: 0.9994 - precision_m: 0.9993 - recall_m: 0.9995 - val_loss: 0.0023 - val_accuracy: 0.9991 - val_f1_m: 0.9995 - val_precision_m: 1.0000 - val_recall_m: 0.9991\n",
      "Epoch 10/10\n",
      "6397/6397 [==============================] - 9s 1ms/step - loss: 0.0016 - accuracy: 0.9995 - f1_m: 0.9994 - precision_m: 0.9994 - recall_m: 0.9995 - val_loss: 6.0240e-04 - val_accuracy: 1.0000 - val_f1_m: 1.0000 - val_precision_m: 1.0000 - val_recall_m: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12523fede88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_samp, y_samp, batch_size=64, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 0.9981390833854675\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "score= model.evaluate(X_test, y_test, verbose=0)  #loss_score, accuracy_score, f1_score, precision_score, recall_score = model.evaluate(X_test, y_test, verbose=2)\n",
    "print('\\nTest accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
