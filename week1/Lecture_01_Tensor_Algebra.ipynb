{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " # Tensor Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "* What is Tensor?\n",
    "* Quick introduction to ***Numpy***\n",
    "* Basic Vector Algebra \n",
    "* Basic Matrix Algebra\n",
    "* Eigen Values - Problems and Applications\n",
    "* Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "<div class=\"slide-title\">\n",
    "    <h3><font color=\"red\">Disclaimer</font></h3>\n",
    "    <b>This is not a math class!</b><br>\n",
    "    <li> Terms and concepts are introduced as needed\n",
    "    <li> NOT complete!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is a Tensor? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In mathematics, a **tensor** is a geometric object that maps in a multi-linear manner geometric vectors, scalars, and other tensors to a resulting tensor. **Vectors and scalars** which are often used in elementary physics and engineering applications, are considered as the simplest tensors...<br>\n",
    "An elementary example of mapping, describable as a tensor, is the **dot product**, which maps two vectors to a scalar. ...\" [Wikipedia]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NumPy - A Python Library for Arrays and Tensors  \n",
    "\n",
    "<center>\n",
    "    <img src=\"IMG/numpy.jpeg\">\n",
    "    <br><br>\n",
    "    <A HREF=\"https://docs.scipy.org/doc/numpy/\">https://docs.scipy.org/doc/numpy/</A>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#comunity convention to name numpy \"np\"\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "NumPy introduction \"on the fly\" - detailed intro in the Lab session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Vector Arithmetic\n",
    "Let's start simple: recall vector notation and some basic vector algebra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notation: we wrtite $\\vec{a}$ to denote elements of some vector space, e.g. $\\vec{a} \\in \\mathbb{R}^n$\n",
    "\n",
    "$\\vec{a} := (a_0, a_1, \\dots, a_n), a_i \\in \\mathbb{R}$\n",
    "\n",
    "See https://en.wikipedia.org/wiki/Vector_space for formal definition of vector spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in numpy we define vectors as 1D arrays\n",
    "a=np.array([1,2,3,4])\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Basic Vector opperations\n",
    "For some example vector space $\\mathbb{R}^n$\n",
    "* addition: $$\\vec{c} = \\vec{a}+\\vec{b} \\rightarrow : \\forall a,b \\in \\mathbb{R}^n: c \\in \\mathbb{R}^n$$\n",
    "\n",
    "* scalar multiplocation: $ h \\vec{a}, h \\in \\mathbb{R} := (ha_0,ha_1,\\dots ha_n) $\n",
    "\n",
    "* **dot product**: $<\\vec{a},\\vec{b}> := c$ ,where $c \\in \\mathbb{R}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.81252653, 3.74872652, 0.8749444 , 4.2438383 ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in numpy:\n",
    "a=np.random.random(4)\n",
    "b=np.random.random(4)\n",
    "a+b*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0791417 , 0.53462484, 0.03289084, 0.12557798])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WARNING:\n",
    "a*b #element wise mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7722353651223098"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dot(b) #this is a dot product !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Some more important vector opperations:\n",
    "* vector norm (formal): $\\|\\vec{a}\\| := \\sqrt{<\\vec{a},\\vec{a}> } $\n",
    "* eucledian norm: $\\|\\vec{a}\\|_2 := \\sqrt{\\sum_i a_i^2 } $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4641016151377544"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in numpy\n",
    "a=np.array([2,2,2])\n",
    "np.linalg.norm(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Some more important vector opperations:\n",
    "* vector norm (formal): $\\|\\vec{a}\\| := \\sqrt{<\\vec{a},\\vec{a}> } $\n",
    "* eucledian norm: $\\|\\vec{a}\\|_2 := \\sqrt{\\sum_i a_i^2 } $\n",
    "* outer product (dyadic product): $\\vec{a} \\otimes \\vec{b} := \\vec{a}\\vec{b}^T$ (Matrix product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Matrix Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Definition\n",
    "A **matrix** $A$ is defined as a $m \\times n$ 2d tensor (rank 2):\n",
    "$A := \\left(\\begin{matrix} a_{00} & a_{01} & \\dots & a_{0n}\\\\ \\vdots & &  & \\vdots\\\\a_{m0} & a_{m1}& \\dots &a_{mn} \\end{matrix} \\right) $\n",
    "\n",
    "* e.g. with $m$ **row vectors** $\\in \\mathbb{R}^n$ and $n$ **column vectors** $\\in \\mathbb{R}^m$\n",
    "* $\\forall a_{ij} \\in \\mathbb{R}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [1, 2, 3, 4],\n",
       "       [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in numpy\n",
    "A=np.array([[1,2,3,4],[1,2,3,4],[5,6,7,8]])\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Motivation I: Matrix as data structure\n",
    "* e.g. to store and process distances between objects\n",
    "<img src=\"IMG/D.png\" width=\"300\">\n",
    "* we will see many examples where matricies hold\n",
    "   * distances \n",
    "   * correlations\n",
    "   * afinity in graphs \n",
    "   * ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Motivation II: linear mappings / equation systems\n",
    "Write system of linear equations\n",
    "<img src=\"IMG/lin_eq.svg\">\n",
    "as $Ax = b$ with\n",
    "<img src=\"IMG/lin_mat.svg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy: Solve the system of equations 3 * x0 + x1 = 9 and x0 + 2 * x1 = 8:\n",
    "a = np.array([[3,1], [1,2]])\n",
    "b = np.array([9,8])\n",
    "np.linalg.solve(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Motivation III: Matrices as operators (tensors)\n",
    "Matrices are widely use as operators (tensors) to apply transformations (mappings) on data vectors. E.g., to represent affine transformations with matrices, we can use **homogeneous coordinates**. This means representing a 2-vector $(x, y)$ as a 3-vector $(x, y, 1)$.\n",
    "\n",
    "$\\vec{a}' = A\\vec{a}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Example: transformations of the unit square in $\\mathbb{R}^2$ [wikipedia].\n",
    "<img src=\"IMG/mat_op.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Special types of Matrices\n",
    "* **Unit Matrix** (or Identity Matrix): $I_n := \\left(\\begin{matrix} 1 & 0 & 0 &\\dots & 0\\\\ 0 & 1 & 0 & \\dots & 0\\\\ \\vdots & & & & \\vdots\\\\ 0 & \\dots& 0 & 1 & 0\\\\0 & 0& \\dots & 0& 1 \\end{matrix} \\right)$\n",
    "with $I_mA = AI_n = A$\n",
    "<br><br>\n",
    "* **Symmetric Matrix**: square Matrix $(m=n)$ where $A^T=A$  \n",
    "<BR><BR>\n",
    "\n",
    "* **Diagonal Matrix**: square Matrix where $a_{mn} := 0, \\quad\\forall m\\neq m$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [0, 2, 0, 0],\n",
       "       [0, 0, 3, 0],\n",
       "       [0, 0, 0, 4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in numpy\n",
    "np.diag([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.identity(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Matrix Arithmetic\n",
    "* **adding matrices** (element wise): $C := A + B$, where $c_{ij} := a_{ij}+b_{ij}  \\forall i\\in m, j \\in n   $\n",
    "<br><br>\n",
    "* **skalar multiplication**: $C := hA$, where $c_{ij} := ha_{ij}  \\forall i\\in m, j \\in n   $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **inner product** (matrix multiplication):\n",
    "<img SRC=\"IMG/matmul.gif\">\n",
    "https://www.reddit.com/r/educationalgifs/comments/5il2xm/matrix_multiplication/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Matrix Inverse\n",
    "\n",
    "The inverse $A^{-1}$ of a quadratic Matrix $A$ is defined as: $A^{-1}A = AA^{-1} = I$\n",
    "\n",
    "**Complexity:** $O(n^3)$ whens solving the above equation via Gauss-Jorden.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Changing the Basis of a Vector Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Definition:\n",
    "a **set** B of elements (**vectors**) in a **vector space** $V$ is called a **basis**, if every element of $V$ may be written in a unique way as a (finite) **linear combination** of elements of B. The coefficients of this linear combination are referred to as components or **coordinates** on B of the vector. The elements of a basis are called basis vectors [wikipedia]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Simple Example:\n",
    "In $\\mathbb{R}^2$, the ***eucledian*** basis is the set of the two vectors $\\vec{e_0} := (1,0)^T, \\vec{e_1} := (0,1)^T$.\n",
    "    \n",
    "Every point $\\vec{p}:=(p_0,p_1) \\in \\mathbb{R}^2$ can be expressed by it's **coordinates** $x,y$ in the form of $p_0:=x\\vec{e_0}$ and $p_1:=y\\vec{e_1}$   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"IMG/basis1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Alternative Basis\n",
    "The basis of vector space is not unique: it is very easy to find new sets of basis vectors.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"IMG/basis2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Optional Properties of Basis Sets\n",
    "* othortogonal\n",
    "* orthonormal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Changing the Basis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Eigen Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One of the re-accuring questions is: how to find the ***\"best\"*** basis for a given problem/data. Decomposition into ***Eigen Values*** and ***Eigen Vectors*** provide a comon solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Definition\n",
    "An eigenvector of a linear transformation $T$ is a non-zero vector that changes by only a scalar factor when that linear transformation is applied to it. This condition can be written as:\n",
    "\n",
    "$ T(\\mathbf {v} )=\\lambda \\mathbf {v} $\n",
    "\n",
    "where $\\lambda$ is a scalar, known as the ***eigenvalue*** associated with the ***eigenvector*** v.\n",
    "\n",
    "If the vector space $V$ is finite-dimensional, then the linear transformation $T$ can be represented as a **square matrix $A$** , and the vector $v$ by a **column vector**, rendering the above mapping as a matrix multiplication on the left-hand side and a scaling of the column vector on the right-hand side in the equation [wikipedia]\n",
    "\n",
    "$ A\\mathbf {v} =\\lambda \\mathbf {v}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Eigen Decomposition\n",
    "for a squared, diagonizable matrix $M$ of size $n \\times n$:\n",
    "\n",
    "* we can find $n$ **eigen vectors** $q_i$ with **eigen values** $\\lambda_i$ \n",
    "\n",
    "* we can decompose $M$ into $M = Q \\Lambda Q^{-1} $\n",
    "    * where $Q$ is a matrix of the eigenvectors\n",
    "    * $\\Lambda$ a diagonal matrix with the $\\lambda_i$ on the diagonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Intuition\n",
    "* Number of non zero eigenvalues gives the \"intrinsic dimension/rank\" of the data\n",
    "* Eigenvectors form **new basis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a numpy example\n",
    "A=np.diag((1, 1, 0))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "v,V=np.linalg.eig(A)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#a bit more complex example\n",
    "A=np.array([[1,1,0,0],[3,3,0,0],[2,2,0,0],[4,4,0,0]])\n",
    "v,V=np.linalg.eig(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 4.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        , -0.70710678, -0.18257419],\n",
       "       [ 0.        ,  0.        ,  0.70710678, -0.54772256],\n",
       "       [ 1.        ,  0.        ,  0.        , -0.36514837],\n",
       "       [ 0.        ,  1.        ,  0.        , -0.73029674]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  4.        ,  0.        , -2.92118697])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[3]*V[3,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Problems with Eigen Decompositions \n",
    "* only for diagonizable, quared marticies\n",
    "* but, matricies hoding data are usually not square (more data samples than data dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Definition [wikipedia]: \n",
    "Suppose $M$ is a $m \\times n$ matrix whose entries come from the field of real numbers or the field of complex numbers. Then there exists a factorization, called a **singular value decomposition** of $M$, of the form\n",
    "\n",
    "$ \\mathbf {M} =\\mathbf {U} {\\boldsymbol {\\Sigma }}\\mathbf {V} ^{*}$\n",
    "\n",
    "where\n",
    "\n",
    "* $U$ is an $m \\times m$ unitary ($U^*U=I$) matrix,\n",
    "* $\\Sigma$ is a diagonal $m \\times n$ matrix with non-negative real numbers, the **singular values**, on the diagonal,\n",
    "* $V$ is an $n \\times n$ unitary matrix, and $V^∗$ is the conjugate transpose of $V$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Intuition:** $M$ is an $m \\times$ m real square matrix with positive determinant: $U, V^*$, and $\\Sigma$ are real $m \\times m$ matrices as well. $\\Sigma$ can be regarded as a **scaling** matrix, and $U, V^∗$ can be viewed as **rotation** matrices [wikipedia]:\n",
    "\n",
    "<img src=\"IMG/svg.png\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0]\n",
      " [0 0 0 2]\n",
      " [0 3 0 0]\n",
      " [0 0 0 0]\n",
      " [2 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#example \n",
    "M = np.array([ [1, 0, 0, 0], [0,0,0,2], [0,3,0,0], [0,0,0,0], [2,0,0,0] ])\n",
    "print(M)\n",
    "U,S,V = np.linalg.svd(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.4472136 ,  0.        ,  0.        , -0.89442719],\n",
       "       [ 0.        ,  0.        , -1.        ,  0.        ,  0.        ],\n",
       "       [-1.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ,  0.        ],\n",
       "       [ 0.        , -0.89442719,  0.        ,  0.        ,  0.4472136 ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.        , 2.23606798, 2.        , 0.        ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0., -1., -0., -0.],\n",
       "       [-1., -0., -0., -0.],\n",
       "       [-0., -0., -0., -1.],\n",
       "       [-0., -0., -1., -0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 0., 2.],\n",
       "       [0., 3., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [2., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now: reconstruct M\n",
    "np.dot(U[:,:4]*S,V) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 3., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [2., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now reconstruct with loss, using only th first 2 of 4 singular values\n",
    "np.dot(U[:,:2]*S[:2],V[:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "livereveal": {
   "enable_chalkboard": true,
   "footer": "Janis Keuper - WS20",
   "header": "Data Mining: Tensor Algebra"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
