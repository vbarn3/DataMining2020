{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing Data \n",
    "---------------\n",
    "     1)  fillna() method \n",
    "     2)  Forward fill method\n",
    "     3)  Backward fill method\n",
    "     4)  dropna() method\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('DATA/season.csv')\n",
    "\n",
    "# This is our dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling all the NaN with any number or string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your dataframe contains NaN values then you can not do any data analysis operation because NaN doesnt make any sense to you.Sometimes it is better to fill it with any number or string.\n",
    "* To fill all the cells containing NaN with any number or string we will use \n",
    "   > ##### fillna ( your_value_goes_here ) \n",
    "Here we are replacing all the NaN values with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.fillna(0)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Fill Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In various cases filling all NaN with same value leads to wrong conclusions. So we want to fill all the NaN of respective columns with data similar to that column. In the previous example we can see that filling zero in \"day\" column is not meaningful because zero does not denote any condition of day. What if we can fill the data similar to the respective columns. <br>\n",
    "In the forward fill method we fill the value of NaN with the previous value of the same column like if we have NaN value in temp column in fourth row then the fourth row NaN value of temp column will be filled with the value of third row value of same column in this method \n",
    " * This method can be implemented by \n",
    "         \n",
    "         fillna ( method =\" ffill \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.fillna(method='ffill')\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can observe the 4th and 6th column of the temp and day, there is a change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Fill method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just opposite of forward fill method.In this method we will fill the NaN value of a dataframe with the value in the same column but next row value like if we have NaN in temp column in 4th row then we will fill it with data in 5th row in the same column.\n",
    "* This can be implemented by   \n",
    "> fillna ( method = \"bfill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.fillna(method=\"bfill\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>limit=m :</b> If your dataframe is having \"n\" continuous NaN values and you want only \"m\" continuous NaN to fill by forward fill method or backward fill method then you can fill the m countinuous NaN by passing as extra argument in \n",
    "> <b>fillna(method=\"ffill\",limit=m)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation Method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to fill your dataframe column with the value relative to that column but not copied from previous or next row of the same column. Suppose value in a column in row-2 is 30 ,the same in row-4 is 34 and row-3 is NaN in same column. In this case if you apply interpolation you will get 32 in the row-2 in the same column.This is called linear interpolation.There are other types of interpolation exist -\n",
    "* 1) linear\n",
    "* 2) quadratic\n",
    "* 3) polynomial\n",
    "* 4) time etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By default it is linear interpolation\n",
    "df2=df.interpolate()\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note\n",
    "* You can see that only temp column get affected because it contains values\n",
    "* Interpolation only applies to columns which contains values not strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"time\" method:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "     In time method, you can fill the NaN value with data according to time value it will continue with respect to time.\n",
    "For example, if you have data like this-\n",
    "      _____________________\n",
    "     | dates     |  data   |\n",
    "     |___________|_________|\n",
    "     |01-02-2012 |   10    |\n",
    "     |02-02-2012 |   30    |\n",
    "     |03-02-2012 |   50    |\n",
    "     |05-02-2012 |   NaN   |\n",
    "     |06-02-2012 |   110   |\n",
    "     |___________|_________|\n",
    "\n",
    "You can observe that the data is increasing 20 units per day .If you apply interpolation probably you will get answer around 75 by linear method but if you apply time method you will get 90 instead of 75.Now you can see the differece in the values.\n",
    "But there is a problem if you apply time method in dataframe without conveting its index to timestamp from string.\n",
    "The following code will convert the index of df dataframe into timestamp.Here i have passes the dates column in the to_datetime() function it will return the timestamp value of dates column then after i set the dates column as its index.Now we can apply the \"time\" method successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dates'] = pd.to_datetime(df['dates'])\n",
    "df = df.set_index('dates')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.interpolate(\"time\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Droping the rows containing NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Droping rows containing NaN will done in following way -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *  Droping or deleting all the rows which contains atleast on NaN <br>\n",
    " dropna() function will drop all the rows which contains atleast one NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.dropna()\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  *  Droping all the rows which contains all the values NaN <br>\n",
    "To drop all the rows which contains only NaN except index(here date is the index) you need to pass how=\"all\" in dropna() function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.dropna(how=\"all\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Droping all the rows which contains n valid values (n is any natural number)\n",
    "If you want to delete those rows which contain only n=2 valid values.In the same way you can delete for n=1,2,3..etc provided n<=number of columns.Here n is called thresold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.dropna(thresh=1)\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        You can see the row which contains at least on valid values it remains same \n",
    "    and the row doesnt contains atleast one value gets deleted.\"not available\" is not\n",
    "    NaN so it will be considered as valid value for dropna() function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing specific value some another value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "       Suppose your dataframe contains some invalid values and you want to replace it with some other values like 0 or NaN.\n",
    "    In this case special values are 5000 and 2000.You can see the following result where 2000 and 5000 is replaced by NaN\n",
    "    value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df2=df.replace([\"5000\",\"2000\"],np.NaN)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    There is one problem with this approach is it will replace all the values which you have passed in the list with\n",
    "    you your value but in many other cases you dont want it like if you have 50000 in price column it is valid but if\n",
    "    50000 is in name column it is not valid in this case.So you only want to replace 50000 of name column with NaN but\n",
    "    not of price column.\n",
    "    In that case you need to pass the disctionary in the replace column.This disctionary will contain name of the column\n",
    "    and the value you want to replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.replace({\n",
    "    'Age':[\"2000\",\"5000\"],\n",
    "    'No_of_pkg':[\"2000\",\"5000\"],\n",
    "    \"travel_id\":[0]\n",
    "},np.NaN)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    If you want to replace some specific value like 5000 with any other value and so on.In that case you need \n",
    "    to pass the disctionary with all keys which you want to replace and values which you want to replace with.\n",
    "    Here 5000,2000,8 are values to replaced are the keys and np.NaN & 10 are values to be replaced with are value\n",
    "    of the disctionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.replace({\n",
    "    \"5000\":np.NaN,\n",
    "    \"2000\":np.NaN,\n",
    "       8:10\n",
    "})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** All the values in the dataframe that belongs to keys of disctionary will be replaced no matter what column it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing unnecessary characters from columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Suppose your dataframe contains unnecessary characters with your data values. Here years/yrs/Yrs/Years\n",
    "    in Age column, same in the No_of_pkg & Package columns are unnecessary charactors which you dont want \n",
    "    and these charactor will prevent you from applying any kind of operation in data analysis.So you want\n",
    "    to get rid of it.In that case you have to pass regex as a value and column name as a key of the \n",
    "    disctionary which you have passed in the replace() function as well as you also have to set regex=True\n",
    "    and a pass an empty string\n",
    "    \n",
    "* ** <code> [A-Za-z] </code> ** : This is the regex of all the character from A to Z and a to z.\n",
    "* <b><code> \\$ </code></b> : This is the regex for **<code>$</code>** sign.\n",
    "* For futher information about regex go to this link https://medium.com/factory-mind/regex-tutorial-a-simple-cheatsheet-by-examples-649dc1c3f285\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df2.replace({\n",
    "    'Age':'[A-Za-z]',\n",
    "    'No_of_pkg':'[A-Za-z]',\n",
    "    'Package':'\\$'\n",
    "},\"\",regex=True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping from one list to another list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     If your dataset contains data which is repeating more than once or you want to change some set of string in to\n",
    "     number then you have apply list mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydis={\n",
    "    \"name\":[\"Shahid\",\"Adrika\",\"Bikash\",\"Ashish\",\"Ganesh\",\"Zahid\",\"Mohan\",\"Sohan\"],\n",
    "    \"grades\":[\"poor\",\"excellent\",\"very good\",\"average\",\"good\",\"very good\",\"outstanding\",\"poor\"]\n",
    "      }\n",
    "df=pd.DataFrame(mydis)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.replace([\"poor\",\"average\",\"good\",\"very good\",\"excellent\",\"outstanding\"],[5,6,7,8,9,10])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
