{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Lectures\n",
    "    * Statistics Part II\n",
    "    * Bayesian Classifier\n",
    "* Lab\n",
    "    * Classification Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Statistics Part II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "* Basic Probability Theory\n",
    "* Bayes' Theorem\n",
    "* Hypotheses and Statistical Tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic Probability Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "***Probability*** is the measure of the likelihood that an event will occur. ***Probability*** quantifies as a number between $0$ and $1$, where, loosely speaking, $0$ indicates impossibility and $1$ indicates certainty. The higher the probability of an event, the more likely it is that the event will occur. [wikipedia]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Notation and Probability Axioms \n",
    "\n",
    "we write $P(E) \\in [0,1]$ to denote the ***probability*** of event $E$. $P(E)$ follows the following axioms:\n",
    "\n",
    "* $P(E) \\in \\mathbb{R},$ and $P(E)\\ge 0$ for all possible $E$\n",
    "* $P(\\Omega) = 1$ : it is certain that at least one event will occur\n",
    "* $P\\left(\\cup_i E_i\\right) = \\sum_i P(E_i)$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dependence of Events\n",
    "In probability theory, two events are independent, statistically independent, or stochastically independent if the occurrence of one does not affect the probability of occurrence of the other (equivalently, does not affect the odds). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* we write $E_1 \\perp E_1$ for ***independent*** events\n",
    "* $P(E_1, E_2) = P(E_1)P(E_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\rightarrow$ **multiplication** of probabilities if events are independent! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Example 1: Coin flip "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Example 2: Sex of children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### How to compute $P(E_1, E_2)$ if events are dependent, e.g. $E_1$ depends on $E_2$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Conditional Probability\n",
    " $P(E_1, E_2) = P(E_1|E_2)P(E_2)$\n",
    " \n",
    " where $P(E_1|E_2)$ is the ***conditional*** probability of event $E_1$, aka the probability that $E_1$ occurs **after** $P(E_2) = 1$ \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This results in:\n",
    "* $P(E_1|E_2) = P(E_1)$ if events are independent \n",
    "* $P(E_1|E_2) = P(E_1, E_2) \\div P(E_2)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Probability can be quite counter intuitive:\n",
    "Examples based on child sex (assuming 50% chance for a boy or girl an independence for several children):\n",
    "\n",
    "* **Example 1**: What is the probability of both children to be girls $P(B):=0.25$, given the conditional event that the first child is a Girl $P(G):=0.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$P(B|G) = P(B,G) \\div P(G) = P(B) \\div P(G) = 0.25 \\div 0.5 = 0.5 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Probability can be quite counter intuitive:\n",
    "Examples based on child sex (assuming 50% chance for a boy or girl an independence for several children):\n",
    "\n",
    "* **Example 2**: What is the probability of both children to be girls $P(B):=0.25$, given the conditional event that at least one child is a girl $P(L):=0.75$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$P(B|L) = P(B,L) \\div P(L) = P(B) \\div P(L) = 0.25 \\div 0.75 = 0.333 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes' Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In probability theory and statistics, ***Bayes' theorem*** describes the ***probability*** of an event, based on ***prior knowledge*** of conditions that might be related to the event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bayes' Theorem\n",
    "\n",
    "$ P(E|F) = {{ P(F|E)P(E)} \\over { P(F)}}$ for $P(F)>0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Interpretation:\n",
    "* reversing the deduction of a conditional probability\n",
    "* a feature often needed in inference (machine learning) settings (later more)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Example:\n",
    "Suppose that a test for using a particular drug is 99% sensitive and 99% specific. That is, the test will produce 99% true positive results for drug users and 99% true negative results for non-drug users. Suppose that 0.5% of people are users of the drug. What is the probability that a randomly selected individual with a positive test is a drug user? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"IMG/drug.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Experiments: Hypotheses and Statistical Tests\n",
    "Ultimately, we use **statistics** and analyze **probabilities** in order to **draw conclusions**. A common approach in statistics is to start an experiment with a ***hypotheses***, which is then validated by a statistical ***test***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Statistical Inference Pipeline\n",
    "* Formulate Hypotheses \n",
    "* Design Experiment\n",
    "* Collect Data\n",
    "* Test / draw conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Null-Hypotheses\n",
    "* The statement being tested in a test of statistical significance is called the ***null hypothesis***. The test of significance is designed to assess the strength of the evidence against the null hypothesis. Usually, the null hypothesis is a statement of ***'no effect'*** or ***'no difference'***. <br>\n",
    "It is often symbolized as $H_0$.\n",
    "\n",
    "* The statement that is being tested against the null hypothesis is the alternative hypothesis $H_1$.\n",
    "\n",
    "* ***Statistical significance test***: Very roughly, the procedure for deciding goes like this: Take a random sample from the population. If the sample data are consistent with the null hypothesis, then do not reject the null hypothesis; if the sample data are inconsistent with the null hypothesis, then reject the null hypothesis and conclude that the alternative hypothesis is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Significant Tests\n",
    "* $p$-Value (or significance): is, for a given statistical model, the probability that, when the null hypothesis is true, the statistical **test summary** would be greater than or equal to the actual observed results.\n",
    "\n",
    "* at experiment design, a significance threshold $\\alpha$ is chosen\n",
    "* typically, $\\alpha = 0.05$ for scientific experiments "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Tests\n",
    "* t-Test\n",
    "* $\\chi^2$ Test\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### t-Test\n",
    "The ***t-Test*** (also called Studentâ€™s t-Test) compares two averages (means) and tells you if they are different from each other. The t-Test also tells you how significant the differences are; In other words it lets you know if those differences could have happened by chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$ t = \\sqrt{n}{{\\bar{X}-\\mu_0} \\over {\\sigma }}$, where\n",
    "<br>\n",
    "* $\\sigma$ standard deviation (from $n$ samples)\n",
    "* $\\bar{X}$ sampled mean from $n$ samples\n",
    "* $\\mu_0$ mean hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means:  -0.1742441018042721 -0.08266383370246891\n",
      "t = -0.20336431000174643\n",
      "p = 0.8411315954258635\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats #statistics module\n",
    "\n",
    "#Sample Size\n",
    "N = 10\n",
    "#Gaussian distributed data with mean = 2 and var = 1\n",
    "a = np.random.randn(N) + 0.1\n",
    "#Gaussian distributed data with with mean = 0 and var = 1\n",
    "b = np.random.randn(N)\n",
    "\n",
    "## Cross Checking with the internal scipy function\n",
    "t2, p2 = stats.ttest_ind(a,b) \n",
    "print(\"means: \", a.mean(), b.mean())\n",
    "print(\"t = \" + str(t2))\n",
    "print(\"p = \" + str(p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### $\\chi^2$-Test\n",
    "The \"chi-square\" test is used to compare multiple categorical distributions, e.g. is there a significant difference between the category counts of experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Example:\n",
    "<table>\n",
    "    <tr><td>category</td> <td>Exp1</td> <td>Exp2</td> <td>Exp3</td> </tr>\n",
    "    <tr><td>A</td><td>14</td> <td>8</td> <td>12</td> </tr>\n",
    "    <tr><td>B</td> <td>986</td> <td>992</td> <td>988</td> </tr>\n",
    "    \n",
    "</table>\n",
    "Null-Hypotheses: all are the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Expected Values \n",
    "* $E(A) = 11.33$\n",
    "* $E(B) = 988.67$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### ***Pearson Residual***\n",
    "$ R = { {observed - expected} \\over {\\sqrt{expected}}}$\n",
    "\n",
    "<table>\n",
    "    <tr><td>category</td> <td>Exp1</td> <td>Exp2</td> <td>Exp3</td> </tr>\n",
    "    <tr><td>A</td><td>0.79</td> <td>-0.99</td> <td>0.19</td> </tr>\n",
    "    <tr><td>B</td> <td>-0.08</td> <td>0.10</td> <td>-0.02</td> </tr>\n",
    "    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\chi^2 := \\sum_i\\sum_j R_{ij}^2$, where $R_{ij}$ are all elements of the Table.\n",
    "* $\\chi^2 = 1.66$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### In Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=3.5, pvalue=0.6233876277495822)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "chisquare([16, 18, 16, 14, 12, 12], f_exp=[16, 16, 16, 16, 16, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Discussion"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "livereveal": {
   "enable_chalkboard": true,
   "footer": "Janis Keuper - WS20",
   "header": "Data Mining: Week 4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
